"use client";

import { useState, useEffect, useRef } from "react";
import { useRouter } from "next/navigation";
import Image from "next/image";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { toast } from "sonner";
import { ChevronLeft, Send, Home, Sparkles, Check, Mic, MicOff, Radio } from "lucide-react";
import ChatMessage from "@/app/_components/ChatMessage";
import { getElderSession, getElderName } from "@/app/_lib/session";
import { GoogleGenAI, Modality, type LiveServerMessage, type Session } from "@google/genai";

// í™”ë©´ ë‹¨ê³„ íƒ€ì…
type Step = "select" | "analyzing" | "chat" | "saved";

// ëŒ€í™” ë©”ì‹œì§€ íƒ€ì…
interface Message {
  id: string;
  role: "ai" | "user";
  content: string;
  imageBase64?: string;   // ìƒì„±ëœ ì´ë¯¸ì§€ (AI ë©”ì‹œì§€ì—ë§Œ)
  imageMimeType?: string;
}

// ëŒ€í™” íˆìŠ¤í† ë¦¬ í„´ (API ì „ì†¡ìš©)
interface ChatTurn {
  role: "user" | "model";
  parts: Array<{ text: string }>;
}

// ì‚¬ì§„ íƒ€ì…
interface ContextImage {
  id: string;
  image_url: string;
  title: string;
  caption: string;
}

// ê¸°ì–µë³µì› Wizard í˜ì´ì§€
export default function ElderMemoryPage() {
  const router = useRouter();
  const [step, setStep] = useState<Step>("select");
  const [elderId, setElderId] = useState<string | null>(null);
  const [elderName, setElderName] = useState("ì–´ë¥´ì‹ ");

  // ì‚¬ì§„ ëª©ë¡
  const [images, setImages] = useState<ContextImage[]>([]);
  const [imagesLoading, setImagesLoading] = useState(true);

  // ì„ íƒí•œ ì‚¬ì§„
  const [selectedImage, setSelectedImage] = useState<ContextImage | null>(null);

  // ì±„íŒ…
  const [messages, setMessages] = useState<Message[]>([]);
  const [chatHistory, setChatHistory] = useState<ChatTurn[]>([]);
  const [input, setInput] = useState("");
  const [chatLoading, setChatLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const [liveStatus, setLiveStatus] = useState("ë¼ì´ë¸Œ ì—°ê²° ì•ˆ ë¨");
  const [isLiveConnected, setIsLiveConnected] = useState(false);
  const [isLiveMicOn, setIsLiveMicOn] = useState(false);
  const liveSessionRef = useRef<Session | null>(null);
  const reconnectTimerRef = useRef<number | null>(null);
  const reconnectAttemptsRef = useRef(0);
  const shouldReconnectRef = useRef(false);
  const micStreamRef = useRef<MediaStream | null>(null);
  const inputCtxRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const inputSourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const silenceRef = useRef<GainNode | null>(null);
  const playbackCtxRef = useRef<AudioContext | null>(null);
  const playbackTimeRef = useRef(0);
  const liveUserTurnMessageIdRef = useRef<string | null>(null);
  const liveUserTurnDisplayTextRef = useRef("");
  const liveUserTurnRawTextRef = useRef("");
  const liveAiTurnMessageIdRef = useRef<string | null>(null);
  const liveAiTurnDisplayTextRef = useRef("");
  const liveAiTurnRawTextRef = useRef("");

  // ì´ë¯¸ì§€ ìƒì„± ìƒíƒœ
  const [isGenerating, setIsGenerating] = useState(false);
  const [hasGeneratedImage, setHasGeneratedImage] = useState(false);

  // ì €ì¥ í™”ë©´ìš© ë§ˆì§€ë§‰ ì´ë¯¸ì§€
  const [generatedImageBase64, setGeneratedImageBase64] = useState<string | null>(null);
  const [generatedImageMime, setGeneratedImageMime] = useState<string>("image/png");
  const [restorationId, setRestorationId] = useState<string | null>(null);

  // ì„¸ì…˜ ì´ˆê¸°í™” + ì‚¬ì§„ ëª©ë¡ ë¡œë“œ
  useEffect(() => {
    const id = getElderSession();
    const name = getElderName();
    if (!id) {
      router.push("/elder/login?next=memory");
      return;
    }
    setElderId(id);
    if (name) setElderName(name);

    // ì‚¬ì§„ ëª©ë¡ ì¡°íšŒ
    fetch(`/api/elders/${id}/images`)
      .then((r) => r.json())
      .then((data) => setImages(data.images ?? []))
      .catch(() => toast.error("ì‚¬ì§„ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))
      .finally(() => setImagesLoading(false));
  }, [router]);

  // ë©”ì‹œì§€ ì¶”ê°€ ì‹œ ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // í˜ì´ì§€ ì´ë™/ë‹¨ê³„ ë³€ê²½ ì‹œ ìŒì„± ìƒíƒœ ì •ë¦¬
  useEffect(() => {
    if (step !== "chat" && typeof window !== "undefined" && "speechSynthesis" in window) {
      window.speechSynthesis.cancel();
    }
  }, [step]);

  useEffect(() => {
    return () => {
      disconnectLive();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const fetchImageAsBase64 = async (url: string) => {
    const res = await fetch(url);
    if (!res.ok) throw new Error("ì‚¬ì§„ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    const buffer = await res.arrayBuffer();
    const mimeType = res.headers.get("content-type") ?? "image/jpeg";
    return {
      mimeType,
      data: arrayBufferToBase64(buffer),
    };
  };

  const sendInitialPhotoPrompt = async (image: ContextImage) => {
    const session = liveSessionRef.current;
    if (!session) return;

    const { data, mimeType } = await fetchImageAsBase64(image.image_url);
    const initialPrompt = "ì´ ì‚¬ì§„ì„ ë³´ê³  ë”°ëœ»í•˜ê²Œ ì„¤ëª…í•˜ê³ , ê¸°ì–µì„ ë– ì˜¬ë¦´ ì§ˆë¬¸ 1ê°€ì§€ë¥¼ í•´ì£¼ì„¸ìš”.";

    session.sendClientContent({
      turns: {
        role: "user",
        parts: [
          { inlineData: { mimeType, data } },
          { text: initialPrompt },
        ],
      },
      turnComplete: true,
    });
  };

  const resetLiveTurnState = () => {
    liveUserTurnMessageIdRef.current = null;
    liveUserTurnDisplayTextRef.current = "";
    liveUserTurnRawTextRef.current = "";
    liveAiTurnMessageIdRef.current = null;
    liveAiTurnDisplayTextRef.current = "";
    liveAiTurnRawTextRef.current = "";
  };

  const stopReconnect = () => {
    if (reconnectTimerRef.current) {
      window.clearTimeout(reconnectTimerRef.current);
      reconnectTimerRef.current = null;
    }
    reconnectAttemptsRef.current = 0;
  };

  const scheduleReconnect = () => {
    if (reconnectTimerRef.current || !selectedImage) return;
    const attempt = reconnectAttemptsRef.current + 1;
    reconnectAttemptsRef.current = attempt;
    const delay = Math.min(10_000, 1000 * Math.pow(2, attempt - 1));
    setLiveStatus(`ë¼ì´ë¸Œ ì¬ì—°ê²° ì¤‘... (${Math.round(delay / 1000)}s)`);
    reconnectTimerRef.current = window.setTimeout(() => {
      reconnectTimerRef.current = null;
      void connectLive(selectedImage);
    }, delay);
  };

  const stopLiveMic = () => {
    if (liveSessionRef.current) {
      liveSessionRef.current.sendRealtimeInput({ audioStreamEnd: true });
    }
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach((track) => track.stop());
      micStreamRef.current = null;
    }
    processorRef.current?.disconnect();
    processorRef.current = null;
    inputSourceRef.current?.disconnect();
    inputSourceRef.current = null;
    silenceRef.current?.disconnect();
    silenceRef.current = null;

    if (inputCtxRef.current) {
      inputCtxRef.current.close();
      inputCtxRef.current = null;
    }
    setIsLiveMicOn(false);
    if (isLiveConnected) {
      setLiveStatus("ë¼ì´ë¸Œ ì—°ê²°ë¨");
    }
  };

  const startLiveMic = async () => {
    if (!liveSessionRef.current) return;
    if (!navigator.mediaDevices?.getUserMedia) {
      toast.error("ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    micStreamRef.current = stream;

    const AudioCtx =
      window.AudioContext ||
      (window as Window & { webkitAudioContext?: typeof AudioContext }).webkitAudioContext;
    if (!AudioCtx) {
      toast.error("ì´ ë¸Œë¼ìš°ì €ëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const inputCtx = new AudioCtx();
    inputCtxRef.current = inputCtx;
    const inputSource = inputCtx.createMediaStreamSource(stream);
    inputSourceRef.current = inputSource;
    const processor = inputCtx.createScriptProcessor(4096, 1, 1);
    processorRef.current = processor;

    const silence = inputCtx.createGain();
    silence.gain.value = 0;
    silenceRef.current = silence;

    processor.onaudioprocess = (e) => {
      const inputData = e.inputBuffer.getChannelData(0);
      const downsampled = downsampleBuffer(inputData, inputCtx.sampleRate, 16000);
      const int16 = floatTo16BitPCM(downsampled);
      const session = liveSessionRef.current;
      if (session) {
        session.sendRealtimeInput({
          audio: {
            data: arrayBufferToBase64(int16.buffer),
            mimeType: "audio/pcm;rate=16000",
          },
        });
      }
    };

    inputSource.connect(processor);
    processor.connect(silence);
    silence.connect(inputCtx.destination);

    setIsLiveMicOn(true);
    setLiveStatus("ë¼ì´ë¸Œ ìŒì„± ëŒ€í™” ì¤‘");
  };

  const playPcmChunk = (base64: string, mimeType: string) => {
    const rate = parseSampleRate(mimeType) || 24000;
    if (!playbackCtxRef.current) {
      const AudioCtx =
        window.AudioContext ||
        (window as Window & { webkitAudioContext?: typeof AudioContext }).webkitAudioContext;
      if (!AudioCtx) return;
      playbackCtxRef.current = new AudioCtx({ sampleRate: rate });
      playbackTimeRef.current = playbackCtxRef.current.currentTime;
    }

    const ctx = playbackCtxRef.current;
    const pcm = base64ToUint8(base64);
    const float32 = pcm16ToFloat32(pcm);
    const buffer = ctx.createBuffer(1, float32.length, rate);
    buffer.getChannelData(0).set(float32);

    const source = ctx.createBufferSource();
    source.buffer = buffer;
    source.connect(ctx.destination);
    playbackTimeRef.current = Math.max(playbackTimeRef.current, ctx.currentTime);
    source.start(playbackTimeRef.current);
    playbackTimeRef.current += buffer.duration;
  };

  const appendLiveMessage = (role: "ai" | "user", rawText: string) => {
    if (!rawText) return;
    const refs =
      role === "ai"
        ? {
            idRef: liveAiTurnMessageIdRef,
            displayRef: liveAiTurnDisplayTextRef,
            rawRef: liveAiTurnRawTextRef,
          }
        : {
            idRef: liveUserTurnMessageIdRef,
            displayRef: liveUserTurnDisplayTextRef,
            rawRef: liveUserTurnRawTextRef,
          };

    if (!refs.idRef.current) {
      const id = `live-${role}-${Date.now()}`;
      refs.idRef.current = id;
      refs.rawRef.current = rawText;
      refs.displayRef.current = rawText;
      setMessages((prev) => [...prev, { id, role, content: rawText }]);
      return;
    }

    const previousRaw = refs.rawRef.current;
    const previousDisplay = refs.displayRef.current;
    let delta = "";

    if (rawText.startsWith(previousRaw)) {
      delta = rawText.slice(previousRaw.length);
    } else if (previousDisplay.endsWith(rawText)) {
      delta = "";
    } else {
      delta = rawText;
    }

    if (!delta) return;
    const nextDisplay = `${previousDisplay}${delta}`;
    refs.rawRef.current = rawText;
    refs.displayRef.current = nextDisplay;
    const id = refs.idRef.current;
    setMessages((prev) => prev.map((m) => (m.id === id ? { ...m, content: nextDisplay } : m)));
  };

  const finalizeLiveTurnToHistory = () => {
    const userText = liveUserTurnDisplayTextRef.current.trim();
    const aiText = liveAiTurnDisplayTextRef.current.trim();
    if (userText || aiText) {
      setChatHistory((prev) => {
        const next = [...prev];
        if (userText) next.push({ role: "user", parts: [{ text: userText }] });
        if (aiText) next.push({ role: "model", parts: [{ text: aiText }] });
        return next;
      });
    }
  };

  const handleLiveServerMessage = (msg: LiveServerMessage) => {
    const serverContent = msg.serverContent;
    if (!serverContent) return;

    const inputText = serverContent.inputTranscription?.text;
    if (inputText) appendLiveMessage("user", inputText);

    const outputText = serverContent.outputTranscription?.text;
    if (outputText) appendLiveMessage("ai", outputText);

    if (serverContent.turnComplete) {
      finalizeLiveTurnToHistory();
      resetLiveTurnState();
    }

    const parts = serverContent.modelTurn?.parts;
    if (!parts) return;
    for (const part of parts) {
      const inline = part.inlineData;
      if (inline?.data) {
        playPcmChunk(inline.data, inline.mimeType || "audio/pcm;rate=24000");
      }
    }
  };

  const connectLive = async (image: ContextImage) => {
    if (!elderId || liveSessionRef.current) return;

    shouldReconnectRef.current = true;
    setLiveStatus("ë¼ì´ë¸Œ ì—°ê²° ì¤‘...");

    try {
      const tokenRes = await fetch("/api/live/token", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ elderId, elderName }),
      });
      const tokenData = await tokenRes.json();
      if (!tokenRes.ok || !tokenData?.token || !tokenData?.model) {
        setLiveStatus(`ì˜¤ë¥˜: ${tokenData?.error || "í† í° ë°œê¸‰ ì‹¤íŒ¨"}`);
        throw new Error(tokenData?.error || "í† í° ë°œê¸‰ ì‹¤íŒ¨");
      }

      const ai = new GoogleGenAI({
        apiKey: tokenData.token,
        httpOptions: { apiVersion: "v1alpha" },
      });

      const session = await ai.live.connect({
        model: tokenData.model,
        config: { responseModalities: [Modality.AUDIO] },
        callbacks: {
          onopen: () => {
            setLiveStatus("ë¼ì´ë¸Œ ì¤€ë¹„ ì™„ë£Œ");
            setIsLiveConnected(true);
            reconnectAttemptsRef.current = 0;
          },
          onmessage: (msg) => handleLiveServerMessage(msg),
          onerror: () => {
            setLiveStatus("ë¼ì´ë¸Œ ì—°ê²° ì˜¤ë¥˜");
          },
          onclose: (event) => {
            finalizeLiveTurnToHistory();
            resetLiveTurnState();
            liveSessionRef.current = null;
            setIsLiveConnected(false);
            setLiveStatus(
              `ë¼ì´ë¸Œ ì—°ê²° ëŠê¹€ (code ${event.code}${event.reason ? `: ${event.reason}` : ""})`
            );
            stopLiveMic();
            if (shouldReconnectRef.current) {
              scheduleReconnect();
            }
          },
        },
      });

      liveSessionRef.current = session;
      await sendInitialPhotoPrompt(image);
    } catch (err) {
      if (shouldReconnectRef.current) {
        scheduleReconnect();
      }
      throw err;
    }
  };

  const disconnectLive = () => {
    shouldReconnectRef.current = false;
    finalizeLiveTurnToHistory();
    if (liveSessionRef.current) {
      liveSessionRef.current.close();
      liveSessionRef.current = null;
    }
    resetLiveTurnState();
    stopReconnect();
    stopLiveMic();
    setIsLiveConnected(false);
    setLiveStatus("ë¼ì´ë¸Œ ì—°ê²° ì•ˆ ë¨");
  };

  const toggleLiveMic = async () => {
    if (!isLiveConnected) return;
    try {
      if (isLiveMicOn) {
        stopLiveMic();
      } else {
        await startLiveMic();
      }
    } catch {
      toast.error("ë§ˆì´í¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      stopLiveMic();
    }
  };

  // API í˜¸ì¶œ ê³µí†µ í•¨ìˆ˜
  const callMemoryChat = async (options: {
    message: string;
    generateImage?: boolean;
    currentHistory?: ChatTurn[];
    imageOverride?: ContextImage; // ì²« ì„ íƒ ì‹œ state ë°˜ì˜ ì „ ì§ì ‘ ì „ë‹¬
  }) => {
    const targetImage = options.imageOverride ?? selectedImage;
    if (!elderId || !targetImage) return null;

    const res = await fetch("/api/memory/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        elderId,
        imageUrl: targetImage.image_url,
        history: options.currentHistory ?? chatHistory,
        message: options.message,
        generateImage: options.generateImage ?? false,
        restorationId,
      }),
    });

    if (!res.ok) {
      const err = await res.json();
      throw new Error(err.error ?? "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
    }

    return res.json();
  };

  const buildHistoryWithLiveBuffer = (baseHistory: ChatTurn[]) => {
    const snapshot = [...baseHistory];
    const pendingUserText = liveUserTurnDisplayTextRef.current.trim();
    const pendingAiText = liveAiTurnDisplayTextRef.current.trim();

    if (pendingUserText) {
      snapshot.push({ role: "user", parts: [{ text: pendingUserText }] });
    }
    if (pendingAiText) {
      snapshot.push({ role: "model", parts: [{ text: pendingAiText }] });
    }

    return snapshot;
  };

  // ì‚¬ì§„ ì„ íƒ â†’ ë¶„ì„ ì‹œì‘
  const handleSelectImage = async (image: ContextImage) => {
    disconnectLive();
    setSelectedImage(image);
    setStep("analyzing");
    setMessages([]);
    setChatHistory([]);
    setHasGeneratedImage(false);
    setGeneratedImageBase64(null);
    setRestorationId(null);

    try {
      await connectLive(image);
      setStep("chat");
    } catch (err) {
      toast.error((err as Error).message || "ë¼ì´ë¸Œ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      setStep("select");
    }
  };

  // ì¼ë°˜ ëŒ€í™” ì „ì†¡
  const handleSend = async () => {
    const trimmed = input.trim();
    if (!trimmed || chatLoading || isGenerating) return;

    if (liveSessionRef.current && isLiveConnected) {
      liveSessionRef.current.sendClientContent({
        turns: {
          role: "user",
          parts: [{ text: trimmed }],
        },
        turnComplete: true,
      });
      setInput("");
      return;
    }

    const userMsg: Message = { id: `user-${Date.now()}`, role: "user", content: trimmed };
    setMessages((prev) => [...prev, userMsg]);
    setInput("");
    setChatLoading(true);
    try {
      const data = await callMemoryChat({ message: trimmed });
      if (!data) return;

      setMessages((prev) => [
        ...prev,
        { id: `ai-${Date.now()}`, role: "ai", content: data.text },
      ]);

      // íˆìŠ¤í† ë¦¬ ëˆ„ì 
      const newHistory: ChatTurn[] = [
        ...chatHistory,
        { role: "user", parts: [{ text: trimmed }] },
        { role: "model", parts: [{ text: data.text }] },
      ];
      setChatHistory(newHistory);

      if (data.restorationId) setRestorationId(data.restorationId);
    } catch (err) {
      toast.error((err as Error).message || "ë©”ì‹œì§€ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
    } finally {
      setChatLoading(false);
    }
  };

  // ì´ë¯¸ì§€ ë§Œë“¤ê¸° â†’ ì±„íŒ… ì•ˆì— ì¸ë¼ì¸ìœ¼ë¡œ í‘œì‹œ
  const handleGenerateImage = async () => {
    if (isGenerating || chatLoading) return;
    setIsGenerating(true);

    try {
      const historyForImage = buildHistoryWithLiveBuffer(chatHistory);
      const data = await callMemoryChat({
        message: "ì§€ê¸ˆê¹Œì§€ ë‚˜ëˆˆ ê¸°ì–µë“¤ì„ ë°˜ì˜í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
        generateImage: true,
        currentHistory: historyForImage,
      });

      if (!data) return;

      if (!data.imageBase64) {
        toast.error("ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        return;
      }

      const mime = data.imageMimeType ?? "image/png";

      // ì´ë¯¸ì§€ë¥¼ ì±„íŒ… ë§í’ì„ ì— ì¶”ê°€
      const aiMsgId = `ai-img-${Date.now()}`;
      setMessages((prev) => [
        ...prev,
        {
          id: aiMsgId,
          role: "ai",
          content: data.text,
          imageBase64: data.imageBase64,
          imageMimeType: mime,
        },
      ]);

      // íˆìŠ¤í† ë¦¬ ëˆ„ì 
      const newHistory: ChatTurn[] = [
        ...historyForImage,
        { role: "user", parts: [{ text: "ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”." }] },
        { role: "model", parts: [{ text: data.text }] },
      ];
      setChatHistory(newHistory);

      // ì €ì¥ í™”ë©´ìš© ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ê°±ì‹ 
      setGeneratedImageBase64(data.imageBase64);
      setGeneratedImageMime(mime);
      if (data.restorationId) setRestorationId(data.restorationId);

      setHasGeneratedImage(true);
    } catch (err) {
      toast.error((err as Error).message || "ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
    } finally {
      setIsGenerating(false);
    }
  };

  // ê¸°ì–µ í™•ì • â†’ saved í™”ë©´
  const handleConfirm = () => {
    disconnectLive();
    setStep("saved");
    toast.success("ê¸°ì–µì´ ì†Œì¤‘íˆ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!");
  };

  // ì—”í„°í‚¤ ì „ì†¡
  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ë Œë”ë§
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  // ì‚¬ì§„ ì„ íƒ ë‹¨ê³„
  if (step === "select") {
    return (
      <div className="pb-12">
        <button
          onClick={() => router.push("/")}
          className="inline-flex items-center gap-1.5 text-muted-foreground hover:text-foreground text-base font-medium mb-6 transition-colors"
        >
          <ChevronLeft className="size-5" />
          í™ˆìœ¼ë¡œ
        </button>

        <div className="space-y-2 mb-6">
          <h1 className="text-3xl font-bold text-foreground">{elderName}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!</h1>
          <p className="text-base text-muted-foreground">ê¸°ì–µì„ ë˜ì‚´ë¦´ ì‚¬ì§„ì„ ê³¨ë¼ë³´ì„¸ìš”</p>
        </div>

        {imagesLoading ? (
          <div className="flex justify-center py-16">
            <div className="w-10 h-10 border-4 border-violet-300 border-t-violet-600 rounded-full animate-spin" />
          </div>
        ) : images.length === 0 ? (
          <div className="glass rounded-3xl p-10 text-center space-y-3">
            <span className="text-5xl">ğŸ“·</span>
            <p className="text-xl font-semibold text-foreground">ì•„ì§ ë“±ë¡ëœ ì‚¬ì§„ì´ ì—†ì–´ìš”</p>
            <p className="text-base text-muted-foreground">ê°€ì¡±ì—ê²Œ ì‚¬ì§„ ë“±ë¡ì„ ë¶€íƒí•´ì£¼ì„¸ìš”</p>
          </div>
        ) : (
          <div className="grid grid-cols-2 gap-3">
            {images.map((img) => (
              <button
                key={img.id}
                onClick={() => handleSelectImage(img)}
                className="group relative rounded-2xl overflow-hidden aspect-square shadow-md hover:shadow-xl hover:-translate-y-0.5 transition-all duration-200"
              >
                <Image
                  src={img.image_url}
                  alt={img.title || "ì‚¬ì§„"}
                  fill
                  className="object-cover group-hover:scale-105 transition-transform duration-300"
                />
                {img.title && (
                  <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black/70 to-transparent p-3">
                    <p className="text-white text-sm font-medium truncate">{img.title}</p>
                  </div>
                )}
              </button>
            ))}
          </div>
        )}
      </div>
    );
  }

  // ë¶„ì„ ì¤‘ ë¡œë”©
  if (step === "analyzing") {
    return (
      <div className="flex flex-col items-center justify-center min-h-[70vh] gap-6">
        <div className="w-16 h-16 border-4 border-violet-300 border-t-violet-600 rounded-full animate-spin" />
        <div className="text-center space-y-1">
          <p className="text-xl font-semibold text-foreground">ì‚¬ì§„ì„ ì‚´í´ë³´ê³  ìˆì–´ìš”</p>
          <p className="text-base text-muted-foreground">ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...</p>
        </div>
        {selectedImage && (
          <div className="relative w-32 h-32 rounded-2xl overflow-hidden shadow-lg opacity-60">
            <Image src={selectedImage.image_url} alt="ì„ íƒí•œ ì‚¬ì§„" fill className="object-cover" />
          </div>
        )}
      </div>
    );
  }

  // ëŒ€í™” ë‹¨ê³„
  if (step === "chat") {
    return (
      <div className="flex flex-col h-[calc(100vh-64px)]">
        {/* í—¤ë” */}
        <div className="py-3 border-b border-border/50 flex items-center gap-3">
          <button
            onClick={() => {
              disconnectLive();
              setStep("select");
            }}
            className="text-muted-foreground hover:text-foreground transition-colors"
            aria-label="ì‚¬ì§„ ì„ íƒìœ¼ë¡œ ëŒì•„ê°€ê¸°"
          >
            <ChevronLeft className="size-5" />
          </button>
          {selectedImage && (
            <div className="relative w-10 h-10 rounded-xl overflow-hidden shrink-0">
              <Image src={selectedImage.image_url} alt="ì„ íƒí•œ ì‚¬ì§„" fill className="object-cover" />
            </div>
          )}
          <div className="flex-1 min-w-0">
            <p className="text-base font-semibold text-foreground truncate">
              {selectedImage?.title || "ê¸°ì–µë³µì› ëŒ€í™”"}
            </p>
            <p className="text-xs text-muted-foreground">ê¸°ì–µì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”</p>
          </div>
        </div>

        {/* ë©”ì‹œì§€ ëª©ë¡ */}
        <div className="flex-1 overflow-y-auto py-4 space-y-1" role="log">
          {messages.map((msg) => (
            <div key={msg.id}>
              <ChatMessage role={msg.role} content={msg.content} />
              {msg.imageBase64 && (
                <div className="flex justify-start px-1 -mt-2 mb-4">
                  <div className="ml-11 rounded-2xl overflow-hidden shadow-md border border-violet-200 max-w-[78%]">
                    <Image
                      src={`data:${msg.imageMimeType};base64,${msg.imageBase64}`}
                      alt="ë³µì›ëœ ê¸°ì–µ ì´ë¯¸ì§€"
                      width={300}
                      height={300}
                      className="object-cover w-full"
                    />
                  </div>
                </div>
              )}
            </div>
          ))}
          {(chatLoading || isGenerating) && (
            <ChatMessage role="ai" content={isGenerating ? "ê¸°ì–µì„ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ê³  ìˆì–´ìš”..." : "..."} />
          )}
          <div ref={messagesEndRef} />
        </div>

        {/* í•˜ë‹¨ ë²„íŠ¼ ì˜ì—­ */}
        <div className="px-0 pb-2 flex flex-col gap-2">
          {hasGeneratedImage && (
            <Button
              onClick={handleConfirm}
              className="w-full h-12 rounded-2xl bg-gradient-to-r from-emerald-500 to-teal-500 hover:from-emerald-600 hover:to-teal-600 text-white font-semibold text-base shadow-md"
            >
              <Check className="size-5 mr-2" />
              ê¸°ì–µ í™•ì •
            </Button>
          )}
          <Button
            onClick={handleGenerateImage}
            disabled={messages.length < 2 || chatLoading || isGenerating}
            className="w-full h-12 rounded-2xl bg-gradient-to-r from-violet-500 to-indigo-500 hover:from-violet-600 hover:to-indigo-600 text-white font-semibold text-base shadow-md disabled:opacity-40"
          >
            <Sparkles className="size-5 mr-2" />
            {isGenerating ? "ì´ë¯¸ì§€ ë§Œë“œëŠ” ì¤‘..." : "ì´ë¯¸ì§€ ë§Œë“¤ê¸°"}
          </Button>
        </div>

        {/* ì…ë ¥ ì˜ì—­ */}
        <div className="border-t border-border/50 bg-background/80 backdrop-blur-sm pt-3 pb-4">
          <div className="flex items-center justify-between gap-2 mb-2">
            <span className="text-xs text-muted-foreground truncate">{liveStatus}</span>
            <div className="flex items-center gap-2">
              <Button
                type="button"
                variant={isLiveConnected ? "default" : "outline"}
                onClick={() => {
                  if (!selectedImage) return;
                  if (isLiveConnected) {
                    disconnectLive();
                    return;
                  }
                  void connectLive(selectedImage).catch(() => {
                    toast.error("ë¼ì´ë¸Œ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
                  });
                }}
                className="h-9 rounded-xl px-3"
                aria-label={isLiveConnected ? "ë¼ì´ë¸Œ ì¢…ë£Œ" : "ë¼ì´ë¸Œ ì—°ê²°"}
              >
                <Radio className="size-4 mr-1.5" />
                {isLiveConnected ? "ë¼ì´ë¸Œ ON" : "ë¼ì´ë¸Œ OFF"}
              </Button>
              <Button
                type="button"
                variant={isLiveMicOn ? "default" : "outline"}
                onClick={() => void toggleLiveMic()}
                disabled={!isLiveConnected}
                className="h-9 rounded-xl px-3"
                aria-label={isLiveMicOn ? "ë¼ì´ë¸Œ ë§ˆì´í¬ ì¤‘ì§€" : "ë¼ì´ë¸Œ ë§ˆì´í¬ ì‹œì‘"}
              >
                {isLiveMicOn ? <MicOff className="size-4 mr-1.5" /> : <Mic className="size-4 mr-1.5" />}
                {isLiveMicOn ? "ë¼ì´ë¸Œ ìŒì„± ON" : "ë¼ì´ë¸Œ ìŒì„± OFF"}
              </Button>
            </div>
          </div>
          <div className="flex gap-2 items-end">
            <Textarea
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={handleKeyDown}
              placeholder={isLiveConnected ? "ë¼ì´ë¸Œì— ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..." : "ê¸°ì–µì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”..."}
              disabled={chatLoading || isGenerating}
              className="flex-1 resize-none text-lg min-h-[52px] max-h-32 rounded-2xl border-border/70 bg-muted/40 focus:bg-white pr-4 pl-4 transition-colors"
              rows={1}
            />
            <Button
              onClick={handleSend}
              disabled={!input.trim() || chatLoading || isGenerating}
              className="h-[52px] w-[52px] rounded-2xl bg-gradient-to-br from-violet-500 to-indigo-500 hover:from-violet-600 hover:to-indigo-600 text-white flex-shrink-0 shadow-md disabled:opacity-40 transition-all"
              aria-label="ë©”ì‹œì§€ ì „ì†¡"
            >
              <Send className="size-5" />
            </Button>
          </div>
        </div>
      </div>
    );
  }

  // ì €ì¥ ì™„ë£Œ
  if (step === "saved") {
    return (
      <div className="flex flex-col items-center justify-center min-h-[70vh] gap-8 text-center px-4">
        <div className="space-y-3">
          <div className="text-6xl">âœ¨</div>
          <h2 className="text-3xl font-bold text-foreground">ê¸°ì–µì´ ì €ì¥ë˜ì—ˆì–´ìš”!</h2>
          <p className="text-base text-muted-foreground leading-relaxed">
            ì†Œì¤‘í•œ ê¸°ì–µì„ ì•„ë¦„ë‹¤ìš´ ì´ë¯¸ì§€ë¡œ<br />ê°„ì§í•˜ê²Œ ë˜ì—ˆì–´ìš”
          </p>
        </div>

        {/* ì €ì¥ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° */}
        {generatedImageBase64 && (
          <div className="relative w-48 h-48 rounded-3xl overflow-hidden shadow-xl border-2 border-violet-200">
            <Image
              src={`data:${generatedImageMime};base64,${generatedImageBase64}`}
              alt="ì €ì¥ëœ ê¸°ì–µ ì´ë¯¸ì§€"
              fill
              className="object-cover"
            />
          </div>
        )}

        <Button
          onClick={() => router.push("/")}
          className="w-full h-14 rounded-2xl bg-gradient-to-r from-violet-500 to-indigo-500 hover:from-violet-600 hover:to-indigo-600 text-white font-bold text-lg shadow-lg"
        >
          <Home className="size-5 mr-2" />
          í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°
        </Button>
      </div>
    );
  }

  return null;
}

function downsampleBuffer(buffer: Float32Array, inputRate: number, outputRate: number) {
  if (outputRate === inputRate) return buffer;
  const ratio = inputRate / outputRate;
  const newLength = Math.round(buffer.length / ratio);
  const result = new Float32Array(newLength);
  let offset = 0;

  for (let i = 0; i < newLength; i++) {
    const nextOffset = Math.round((i + 1) * ratio);
    let sum = 0;
    let count = 0;
    for (let j = offset; j < nextOffset && j < buffer.length; j++) {
      sum += buffer[j];
      count++;
    }
    result[i] = count ? sum / count : 0;
    offset = nextOffset;
  }
  return result;
}

function floatTo16BitPCM(float32: Float32Array) {
  const output = new Int16Array(float32.length);
  for (let i = 0; i < float32.length; i++) {
    const s = Math.max(-1, Math.min(1, float32[i]));
    output[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
  }
  return output;
}

function arrayBufferToBase64(buffer: ArrayBuffer) {
  const bytes = new Uint8Array(buffer);
  let binary = "";
  for (let i = 0; i < bytes.length; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

function base64ToUint8(base64: string) {
  const binary = atob(base64);
  const bytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  return bytes;
}

function pcm16ToFloat32(bytes: Uint8Array) {
  const view = new DataView(bytes.buffer);
  const float32 = new Float32Array(bytes.byteLength / 2);
  for (let i = 0; i < float32.length; i++) {
    const int16 = view.getInt16(i * 2, true);
    float32[i] = int16 / 0x8000;
  }
  return float32;
}

function parseSampleRate(mimeType: string) {
  const match = /rate=(\d+)/.exec(mimeType || "");
  return match ? Number(match[1]) : null;
}
